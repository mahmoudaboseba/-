{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5679954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity , linear_kernel\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import argparse\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import SimpleRNN , Dropout ,LSTM,Conv1D, GlobalMaxPooling1D, MaxPooling1D , SpatialDropout1D,Activation,Dense, Dropout, Activation, Flatten, Input, concatenate , GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "#import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29d63d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('arabic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f9740d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Mahmoud\\Desktop\\cloud\\full_dataset.tsv\", delimiter = '\\t' , quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f8a78c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['شيخ انا اسفه ف السؤال ده بس في ثوابت ف الدين بتضيع مني هو بجد كان في ايه ف القران وفي معزه اكلتها وحكمها لسه موجود لحد دلوقتي ف حد الزنا !!!!!!'\n",
      " 'شيخ انا بصلي وانا قاعده انا كويسه صحتي حلوه اقدر اني اصلي وانا واقفه بس من 3 سنين جالي الوسواس القهري ف موض ع الصلاه بقيت ممكن اعيد الصلاه بالوضوء 5 او 6 مرات او اكتر ونلقتش حل عير اني اصلي وانا قاعده دلوقتي هل حرام ؟!'\n",
      " 'لو سمحت لو بابا بيفطر رمضان عشان مريض بس المشكله انه مش بيطلع كفارة ّ....ممكن احنا نطلعها من وراه وتسقط عنه!!!وكمان لو عليه ديون من زمان لحد...حاجات بسيطة 20جنيه لحد وحاجات ف الرينج دا بس هو مطنشها ينفع نرجعها لاصحابها من وراه وتسقط عنه!!!!'\n",
      " ...\n",
      " 'وليه بتفهم كلام ربنا غلط عايز تدرس المسيحيه بجد من غير اغلاط وتفهمعا هات الكتاب المقدس مع التفسير وانت هتعرف يعني ايه تكون مسيحي هتحس بسلام هتلاقي كلام ربنا كله محبه لابناءه هتلاقي العدل والخير هنشوف اد ايه بيحبك وعمل علشانك ايه ممكن تاخد كلامي بسخرية ممكن تقول انا قريته بس لو قريته كنت هتبقى مسيحي'\n",
      " '-' '-']\n",
      "['هو حديث ضعيف، وعموما لو معزة كلت المصحف كله فالقرآن ثابت محفوظ. لا تعطي أذنك للجهلة الحمقى فتخسري دينك على حاجات تافهة'\n",
      " 'صلي وانت قائمة وتجاهلي أي وساوس. غير كده لا يجوز'\n",
      " 'يصح في الديون ولا يصح في الكفارات دون علمه وإذنه' ...\n",
      " 'إجابة سؤالك الأول: بدرس المسيحيّة، عشان أقولك وأقول لغيرك: أنت لا تعبد الله وحده، انت مشرك بالله، بوصّل له حقيقة دينه. قبل كلامي، أهلا وسهلا. رفضه: أهلا وسهلا برضه. ------ مين قالك اني بفهم كلام الكتاب المقدس غلط ؟  لما هقول لحضرتك انتي بتعبدي أكثر من إله، بتعبدي أكثر من شخص. هقولك الدليل من كتابك، وبالتفسير المسيحي المعتمد. . الإحساس بالسلام دا ممكن حضرتك تحسّيه، وممكن المسلم يحسّه، وعابد بوذا بيحسّه، والملحد كمان ممكن يحسّه. فمش هو المعيار. المعيار هو موافقة الدين للعقل والفطرة السليمة. . لو قريته هتبقى مسيحي؟ انا قريته من كتب حضرتك اصلا لا تعرفي اسماءها، وكاهن حضرتك اللي بتتناولي عنده وبيصليلك لا يعرفها. غير قراءتي من التفاسير والكتب المسيحية المشهورة، كتفسير تادرس يعقوب،وكتب الأنبا بيشوي والبابا شنودة، وكتب الآباء الأوائل مثل أمبروسيوس، وكيرلس السكندري، ومبقيتش مسيحي ولا حاجة. بالعكس: كل كتاب مسيحي بقرأه يزيد يقيني ان المسيحية شرك بالله.'\n",
      " 'الأنبا رافائيل أسقف كنائس وسط القاهرة يقول: المسيح كان عريان على الصليب. https://www.youtube.com/watch?v=e7Sl4PzBi-4'\n",
      " 'الاب سيداروس - المسيح دخل بطن العدرا وفرش ونام وقال محدش يكلمني غير بعد 9 أشهر https://youtu.be/so-nfVFyepM']\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[: , 0].values\n",
    "y = data.iloc[: , -1].values\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c24dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "arabic_diacritics = re.compile(\"\"\"\n",
    "                             ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    text = re.sub(\"گ\", \"ك\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_diacritics(text):\n",
    "    text = re.sub(arabic_diacritics, '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "\n",
    "def remove_repeating_char(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "        u\"\\u2066\"\n",
    "        u\"\\u2069\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', str(data))\n",
    "\n",
    "def to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_eng(text):\n",
    "    return re.sub(r'[A-Za-z]','',str(text))\n",
    "    \n",
    "import string\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "\n",
    "def replace_numbers(text):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "\n",
    "def remove_whitespaces(text):\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def remove_stopwords(words, stop_words):\n",
    "\n",
    "    return [word for word in words if word not in stop_words]\n",
    "\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "def lemmatize_words(words):\n",
    "    \"\"\"Lemmatize words in text\"\"\"\n",
    "\n",
    "    lemmatizer = ISRIStemmer()\n",
    "    return ' '.join([lemmatizer.stem(word) for word in words])\n",
    "\n",
    "def text2words(text):\n",
    "  return word_tokenize(text)\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = remove_emojis(text)\n",
    "    text = remove_eng(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_punctuations(text)\n",
    "    text = normalize_arabic(text)\n",
    "    text = remove_diacritics(text)\n",
    "    text = remove_repeating_char(text)\n",
    "    text = to_lowercase(text)\n",
    "    text = replace_numbers(text)\n",
    "    words = text2words(text)\n",
    "    words = remove_stopwords(words, stop_words)\n",
    "    words = lemmatize_words(words)\n",
    "    return ''.join(words)\n",
    "\n",
    "def normalize_corpus(corpus):\n",
    "  return [normalize_text(t) for t in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f5edbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = normalize_corpus(X)\n",
    "#y = normalize_corpus(y)\n",
    "print(X)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a8a7adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), tokenizer=text2words,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1)\n",
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "993f2447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a question: \n",
      "هل السرقه حرام\n",
      "chat :  نعم\n",
      "Please enter a question: \n",
      "ما حكم الدين فى الزنااا\n",
      "chat :  الحمد لله كفر بالله وصد عن سبيله\n",
      "Please enter a question: \n",
      "ما الزنااا\n",
      "chat :  الإنسان لا يبحث عن وزن الإثم بقدر بحثه عن التوبة والاعتذار لله سبحانه.\n",
      "Please enter a question: \n",
      "هل الزنا حرام\n",
      "chat :  مشوّهين فطرياً دي كلمة لا أحب استعمالها وأنا في سياق الطب النفسي. ربما منتكسين نفسياً أقرب في الوصف.\n",
      "Please enter a question: \n",
      "ما حكم الدين فى الزانى\n",
      "chat :  الحمد لله. الحرمان من وعد الله بالجنة، وحصول الإثم في قلبه، واسوداد جزء من قلبه، هذه أكبر عقوبة! الزاني خرج ممن وعد الله بدخول الجنة، فهو عاص لله، واقع في ما هو من أكبر الكبائر، فإما أن يتوب توبة تمحو هذه الخطيئة العظيمة، ويعود إلى دائرة الموعودين بالجنة. وإما أن يبقى مذلولا في مشيئة الله كسائر أهل الكبائر!\n",
      "Please enter a question: \n",
      "كلمنى عن الجنه والنار وازاى ارضى ربنا\n",
      "chat :  تفعل الفرائض وتجتنب المحرمات وتحسن أخلاقك، وإذا أذنبت فتب. وتحب الخير للمسلمين ويسلم صدرك لهم.\n",
      "Please enter a question: \n",
      "هل انت اجتماعى\n",
      "chat :  إلى حد ما لست اجتماعيا\n",
      "Please enter a question: \n",
      "بارك الله فيك\n",
      "chat :  سؤالك غير مفهوم يا أخي اختصر ووضح الله يكرمك\n",
      "Please enter a question: \n",
      "انا امدحك\n",
      "chat :  مش لازم مصلحته هو، ممكن مصلحة الوطن، أو مصلحة الدعوة، أو حتى المصلحة بتاعت أحمد عز، احنا مالنا :)\n",
      "Please enter a question: \n",
      "سلام عليكم\n",
      "chat :  وعليكم السلام ممكن نتعرف؟\n",
      "Please enter a question: \n",
      "سلام\n",
      "chat :  وعليكم السلام ممكن نتعرف؟\n",
      "Please enter a question: \n",
      "jkfbvh\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    \n",
    "    question = [input('Please enter a question: \\n')]\n",
    "    nor_input = normalize_corpus(question)\n",
    "    if (len(nor_input[0]) != 0):\n",
    "        nor_input = vectorizer.transform(nor_input)\n",
    "\n",
    "        rank = linear_kernel(X , nor_input)\n",
    "        #print(rank)\n",
    "        sim_scores = list(enumerate(rank))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[0:1]\n",
    "        courses_indices = [i[0] for i in sim_scores]\n",
    "        for i in courses_indices:\n",
    "            print('chat : ',data['Answer'].iloc[i])\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea1ed91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5c477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
